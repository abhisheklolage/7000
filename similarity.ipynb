{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "similarity.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "5hzinPvOeAt1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "433189c1-e6b4-4f8e-c8cb-f8d0afa1dd7b"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp drive/My\\ Drive/bigdata/similarity/true-classes.npz drive/My\\ Drive/bigdata/similarity/resnet50-pretrained-np-dump.npz drive/My\\ Drive/bigdata/similarity/resnet50-qs-1282015-dump.npz.zip .\n",
        "!unzip resnet50-qs-1282015-dump.npz.zip"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Archive:  resnet50-qs-1282015-dump.npz.zip\n",
            "  inflating: resnet50-qs-1282015-dump.npz  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TfttbxMliVt4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "5d1eddc6-cdd7-41c1-d235-e3ded134d82a"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datasets\t     resnet50-pretrained-np-dump.npz\n",
            "drive\t\t     resnet50-qs-1282015-dump.npz\n",
            "extracted.txt\t     resnet50-qs-1282015-dump.npz.zip\n",
            "feature-dump.npz     resnet50-qs-dump.npz\n",
            "nn-qs-answers.npz    sample_data\n",
            "nn-true-answers.npz  true-classes.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R6OC3YISeF9a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#\n",
        "# This code is for doing similarity search on set of images.\n",
        "# Image features generated using:\n",
        "# resnet pretrained-embeddings, resnet importance sampling trained\n",
        "# Sketches (compressed representations) of features generated using\n",
        "# grid, quadsketch, quadsketch variant\n",
        "#\n",
        "\n",
        "## imports\n",
        "# libraries\n",
        "import numpy as np\n",
        "from numpy import linalg as LA\n",
        "\n",
        "## gloabls\n",
        "true_training_categories   = []\n",
        "true_query_categories      = []\n",
        "true_training_features     = []\n",
        "true_query_features        = []\n",
        "sketched_training_features = []\n",
        "sketched_query_features    = []\n",
        "\n",
        "true_answers = []\n",
        "sketched_answers = []\n",
        "\n",
        "DIM       = 2048\n",
        "## functions\n",
        "\n",
        "def query(Q, K):\n",
        "    '''\n",
        "    Q could be the original or the sketched feature vector\n",
        "    Returns K nearest images\n",
        "    '''\n",
        "    pass\n",
        "\n",
        "def evaluate(K):\n",
        "    ## get class of vector\n",
        "\n",
        "    ## original feature based nearest neighbor\n",
        "    #print(len(true_query_features))\n",
        "    #print(len(true_query_categories))\n",
        "    #print(true_query_categories[0])\n",
        "    ## for every query compute the NN\n",
        "    \n",
        "    print(\"# of queries:\", len(true_query_features))\n",
        "    \n",
        "    print(\"Computing for true features...\")\n",
        "    percent = 0\n",
        "    \n",
        "    for q in range(len(true_query_features)):\n",
        "        feature = true_query_features[q]\n",
        "        category = true_query_categories[q]\n",
        "\n",
        "        min_distance = 100000000\n",
        "        who = -1     # is the nearest neighbor\n",
        "        which = -1   # category\n",
        "        if((q + 1) % 100 == 0):\n",
        "            print(q + 1, \" queries done...\")\n",
        "            percent += 10\n",
        "        for r in range(len(true_training_features)):\n",
        "            euc_dis = LA.norm(true_training_features[r] - true_query_features[q])\n",
        "            if(euc_dis < min_distance):\n",
        "                min_distance = euc_dis\n",
        "                who = r # index in the database\n",
        "                which = true_training_categories[r]\n",
        "        #print(min_distance)\n",
        "        true_answers.append([category, which, who])\n",
        "\n",
        "    ## sketched feature based nearest neighbor\n",
        "    print(\"\\nComputing for sketched features...\")\n",
        "    percent = 0\n",
        "    for q in range(len(sketched_query_features)):\n",
        "        feature = sketched_query_features[q]\n",
        "        category = true_query_categories[q]\n",
        "\n",
        "        min_distance = 100000000\n",
        "        who = -1     # is the nearest neighbor\n",
        "        which = -1   # category\n",
        "        if((q + 1) % 100 == 0):\n",
        "            print(q + 1, \"% queries done...\")\n",
        "            percent += 10\n",
        "        for r in range(len(sketched_training_features)):\n",
        "            euc_dis = LA.norm(sketched_training_features[r] - sketched_query_features[q])\n",
        "            if(euc_dis < min_distance):\n",
        "                min_distance = euc_dis\n",
        "                who = r # index in the database\n",
        "                which = true_training_categories[r]\n",
        "        #print(min_distance)\n",
        "        sketched_answers.append([category, which, who])\n",
        "        \n",
        "        \n",
        "    # Computing distortion\n",
        "    \n",
        "    exact_counter = 0\n",
        "    class_counter = 0\n",
        "    distortion = 0.0\n",
        "    for q in range(len(sketched_query_features)):\n",
        "        true_answer_feature = true_training_features[true_answers[q][2]]\n",
        "        dd2 = LA.norm(true_query_features[q] - true_answer_feature)\n",
        "        \n",
        "        if dd2 < 1e-3:\n",
        "          distortion += 1.0\n",
        "          exact_counter += 1\n",
        "        else:\n",
        "          dd1 = LA.norm(true_training_features[sketched_answers[q][2]] - true_query_features[q])\n",
        "          distortion += dd1/dd2\n",
        "          if(true_answers[q][2] == sketched_answers[q][2]): # exact nearest neighbor pt\n",
        "            exact_counter += 1\n",
        "          #else:\n",
        "            # not the exact same neighbor, but same class?\n",
        "            #if(true_answers[q][1] == sketched_answers[q][1]) # means qs, and original features predicted same class\n",
        "              #class_counter += 1\n",
        "              #if(true_answers[q][1] == true_answers[q][0])   # both predicted the correct category\n",
        "            \n",
        "                     \n",
        "    print(\"EVAL\")\n",
        "    print(len(true_answers))\n",
        "    print(len(sketched_answers))\n",
        "    print(\"EVAL\")\n",
        "    \n",
        "    ##\n",
        "    distortion = distortion / len(sketched_query_features)\n",
        "    accuracy = exact_counter / len(sketched_query_features)\n",
        "    print(\"Avg Distortion: \", distortion)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    ##\n",
        "    \n",
        "    # save the answers?\n",
        "    np.savez(\"nn-true-answers.npz\", true_answers=true_answers)\n",
        "    np.savez(\"nn-qs-answers.npz\"  , sketched_answers=sketched_answers)\n",
        "    np.savez(\"stats.npz\", accuracy=accuracy, distortion=distortion)\n",
        "    return true_answers, sketched_answers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WHKFXH4jeMhf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1397
        },
        "outputId": "6c266f5e-f900-40f1-df35-9ae512b2bd87"
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    ## decompressed\n",
        "    # dataset =\n",
        "    # queries =\n",
        "    ##\n",
        "    \n",
        "    # first entry of both is [], for class indexing 1-257\n",
        "    true_file = np.load(\"true-classes.npz\", allow_pickle=True)\n",
        "    train_ex = true_file['tr_paths'] # has first element as []\n",
        "    query_ex = true_file['qr_paths'] # has first element as []\n",
        "    for category in range(1, 258):\n",
        "        for im in train_ex[category]:\n",
        "            true_training_categories.append(int(im[1]))\n",
        "        for im in query_ex[category]:\n",
        "            true_query_categories.append(int(im[1]))\n",
        "\n",
        "    ## from the colab file, as is, no change required\n",
        "    true_features_file = np.load(\"resnet50-pretrained-np-dump.npz\", allow_pickle=True)\n",
        "    true_training_features = true_features_file['emb_training']\n",
        "    true_query_features = true_features_file['emb_query']\n",
        "\n",
        "    ## from the cpp codes, requires to segregate training and query\n",
        "    sketched_features_file = np.load(\"resnet50-qs-1282015-dump.npz\", allow_pickle=True)\n",
        "    #print(sketched_features_file.files)\n",
        "    all_sketched_features = sketched_features_file['qstq']\n",
        "    all_sketched_features_N = [all_sketched_features[i * DIM: (i + 1) * DIM] for i in range(int(len(all_sketched_features)/2048))]\n",
        "    NUM_QUERY  = len(true_query_features)\n",
        "    NUM_TRAIN  = len(true_training_features)\n",
        "    sketched_training_features = all_sketched_features_N[: NUM_TRAIN]\n",
        "    sketched_query_features = all_sketched_features_N[NUM_TRAIN: len(all_sketched_features_N)]\n",
        "\n",
        "    \n",
        "    start = time.time()\n",
        "    true_answers, sketched_answers = evaluate(1)\n",
        "    end = time.time()\n",
        "    print(\"Time reqired\", end - start)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of queries: 2963\n",
            "Computing for true features...\n",
            "100  queries done...\n",
            "200  queries done...\n",
            "300  queries done...\n",
            "400  queries done...\n",
            "500  queries done...\n",
            "600  queries done...\n",
            "700  queries done...\n",
            "800  queries done...\n",
            "900  queries done...\n",
            "1000  queries done...\n",
            "1100  queries done...\n",
            "1200  queries done...\n",
            "1300  queries done...\n",
            "1400  queries done...\n",
            "1500  queries done...\n",
            "1600  queries done...\n",
            "1700  queries done...\n",
            "1800  queries done...\n",
            "1900  queries done...\n",
            "2000  queries done...\n",
            "2100  queries done...\n",
            "2200  queries done...\n",
            "2300  queries done...\n",
            "2400  queries done...\n",
            "2500  queries done...\n",
            "2600  queries done...\n",
            "2700  queries done...\n",
            "2800  queries done...\n",
            "2900  queries done...\n",
            "\n",
            "Computing for sketched features...\n",
            "100 % queries done...\n",
            "200 % queries done...\n",
            "300 % queries done...\n",
            "400 % queries done...\n",
            "500 % queries done...\n",
            "600 % queries done...\n",
            "700 % queries done...\n",
            "800 % queries done...\n",
            "900 % queries done...\n",
            "1000 % queries done...\n",
            "1100 % queries done...\n",
            "1200 % queries done...\n",
            "1300 % queries done...\n",
            "1400 % queries done...\n",
            "1500 % queries done...\n",
            "1600 % queries done...\n",
            "1700 % queries done...\n",
            "1800 % queries done...\n",
            "1900 % queries done...\n",
            "2000 % queries done...\n",
            "2100 % queries done...\n",
            "2200 % queries done...\n",
            "2300 % queries done...\n",
            "2400 % queries done...\n",
            "2500 % queries done...\n",
            "2600 % queries done...\n",
            "2700 % queries done...\n",
            "2800 % queries done...\n",
            "2900 % queries done...\n",
            "EVAL\n",
            "2963\n",
            "2963\n",
            "EVAL\n",
            "Avg Distortion:  1.0016585672943727\n",
            "Accuracy: 0.847789402632467\n",
            "Time reqired 932.3139412403107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aRBOqJO4J-Iz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive/My\\ Drive/bigdata/similarity/results/\n",
        "!cp nn-true-answers.npz drive/My\\ Drive/bigdata/similarity/results/\n",
        "!cp nn-qs-answers.npz drive/My\\ Drive/bigdata/similarity/results/\n",
        "!cp stats.npz drive/My\\ Drive/bigdata/similarity/results/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IbfEdvePlgMb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "outputId": "0fc9712a-209e-4b7d-bce0-6f375e9b9bb1"
      },
      "cell_type": "code",
      "source": [
        "TEST_QUERY = 10\n",
        "print(true_answers[TEST_QUERY][0], true_answers[TEST_QUERY][1], true_answers[TEST_QUERY][2])  # true cat, computed cat, because of which vector\n",
        "print(sketched_answers[TEST_QUERY][0], sketched_answers[TEST_QUERY][1], sketched_answers[TEST_QUERY][2])\n",
        "\n",
        "\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 135 13608\n",
            "2 135 13608\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ecmcJXxBqK0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "40282234-8145-454b-b430-f93f997375bf"
      },
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "pprint(sketched_training_features[0])\n",
        "pprint(sketched_training_features[1])\n",
        "pprint(sketched_query_features[0])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "array([0.5    , 0.53125, 0.5    , ..., 0.5    , 0.5    , 0.53125],\n",
            "      dtype=float32)\n",
            "array([0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5], dtype=float32)\n",
            "array([0.5    , 0.53125, 0.5    , ..., 0.5    , 0.5    , 0.53125],\n",
            "      dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "itrsN89AeO2q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "235ae912-68f9-4be1-862f-329f3e6d613a"
      },
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 863836\n",
            "drwxr-xr-x 3 root root      4096 Apr 30 02:24 datasets\n",
            "drwx------ 3 root root      4096 Apr 30 02:23 drive\n",
            "-rw-r--r-- 1 root root   1484977 Apr 30 02:24 extracted.txt\n",
            "-rw-r--r-- 1 root root    803304 Apr 30 02:29 feature-dump.npz\n",
            "-rw-r--r-- 1 root root     71378 Apr 30 07:25 nn-qs-answers.npz\n",
            "-rw-r--r-- 1 root root     71370 Apr 30 07:25 nn-true-answers.npz\n",
            "-rw------- 1 root root 250733032 Apr 30 06:20 resnet50-pretrained-np-dump.npz\n",
            "-rw-rw-r-- 1 root root 250732738 Apr 30 00:08 resnet50-qs-1282015-dump.npz\n",
            "-rw------- 1 root root 127796646 Apr 30 06:20 resnet50-qs-1282015-dump.npz.zip\n",
            "-rw------- 1 root root 250732738 Apr 30 04:45 resnet50-qs-dump.npz\n",
            "drwxr-xr-x 1 root root      4096 Apr 26 16:21 sample_data\n",
            "-rw-r--r-- 1 root root       498 Apr 30 07:25 stats.npz\n",
            "-rw-r--r-- 1 root root   2092181 Apr 30 06:20 true-classes.npz\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "features.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "dg4b7jD_M8z6",
        "colab_type": "code",
        "outputId": "ec421248-6622-4a83-9d17-c3bf7e34d82c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "cell_type": "code",
      "source": [
        "#\n",
        "# This code is for converting images to embeddings, using pretrained and trained\n",
        "# models\n",
        "#\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "from keras import Model\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dt6MHxThkqhh",
        "colab_type": "code",
        "outputId": "7009300a-9d2d-4fd5-d6b0-be42fd868e07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        }
      },
      "cell_type": "code",
      "source": [
        "!ls \n",
        "!ls datasets/"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datasets  drive  extracted.txt\tfeature-dump.npz  sample_data  true-classes.npz\n",
            "caltech256  caltech256.py  datautils.py  __init__.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5gFC9Ep_gAaS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!tar -xvf drive/My\\ Drive/256_ObjectCategories.tar > extracted.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KmK9TMDQhRpm",
        "colab_type": "code",
        "outputId": "b497bd01-a5e1-4ce1-bdd2-69b71711ee24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p datasets\n",
        "!cp drive/My\\ Drive/__init__.py datasets/\n",
        "!cp drive/My\\ Drive/caltech256.py datasets/\n",
        "!cp drive/My\\ Drive/datautils.py datasets/\n",
        "!mv 256_ObjectCategories/ datasets/caltech256\n",
        "!ls datasets/\n",
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "caltech256  caltech256.py  datautils.py  __init__.py\n",
            "datasets  drive  extracted.txt\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DvCwQG7wi-cj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "image_types = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
        "def list_images(basePath, contains=None):\n",
        "    # return the set of files that are valid\n",
        "    return list_files(basePath, validExts=image_types, contains=contains)\n",
        "def list_files(basePath, validExts=None, contains=None):\n",
        "    # loop over the directory structure\n",
        "    for (rootDir, dirNames, filenames) in os.walk(basePath):\n",
        "        # loop over the filenames in the current directory\n",
        "        for filename in filenames:\n",
        "            # if the contains string is not none and the filename does not contain\n",
        "            # the supplied string, then ignore the file\n",
        "            if contains is not None and filename.find(contains) == -1:\n",
        "                continue\n",
        "\n",
        "            # determine the file extension of the current file\n",
        "            ext = filename[filename.rfind(\".\"):].lower()\n",
        "\n",
        "            # check to see if the file is an image and should be processed\n",
        "            if validExts is None or ext.endswith(validExts):\n",
        "                # construct the path to the image and yield it\n",
        "                imagePath = os.path.join(rootDir, filename)\n",
        "                yield imagePath\n",
        "\n",
        "def get_images(QUERY):\n",
        "    '''\n",
        "    Returns training, querying dataset as a list of lists, where inner list is\n",
        "    of categories. Category starts from index 1 and not 0. This just gives list\n",
        "    of paths.\n",
        "    '''\n",
        "    labels           = []\n",
        "    dataset          = []\n",
        "    image_paths      = list(list_images(\"./datasets/caltech256\"))\n",
        "    stats = {}\n",
        "    for (i, image_path) in enumerate(image_paths):\n",
        "        label = int(image_path.split(os.path.sep)[-1].split(\"_\")[0])\n",
        "        if(label not in stats):\n",
        "            stats[label] = 1\n",
        "        else:\n",
        "            stats[label] += 1\n",
        "        dataset.append([image_path, label])\n",
        "    dataset = sorted(dataset, key = lambda x: x[1])\n",
        "    training_images = [[]]\n",
        "    query_images    = [[]]\n",
        "    dataset_ptr     = 0\n",
        "    for cat in range(1, 258): # 257 labels\n",
        "        num_queries = int(stats[cat] * QUERY)\n",
        "\n",
        "        start = dataset_ptr\n",
        "        mid   = dataset_ptr + num_queries\n",
        "        end   = dataset_ptr + stats[cat]\n",
        "\n",
        "        query_images.append(dataset[start: mid])\n",
        "        training_images.append(dataset[mid: end])\n",
        "\n",
        "        dataset_ptr += stats[cat]\n",
        "\n",
        "\n",
        "    for cat in range(1, 258):\n",
        "        #print(len(query_images[cat]), len(training_images[cat]), stats[cat])\n",
        "        assert(len(query_images[cat]) + len(training_images[cat]) == stats[cat])\n",
        "    print(\"Splitting done\")\n",
        "\n",
        "    return training_images, query_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wpaauLUOg8W3",
        "colab_type": "code",
        "outputId": "1ef7d7da-9917-4541-8a06-dd97b7e78e29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "cell_type": "code",
      "source": [
        "## get dataset splits\n",
        "import os\n",
        "training_paths, query_paths = get_images(0.10)\n",
        "print(\"DONE\")\n",
        "\n",
        "\n",
        "## training code, get model\n",
        "## pretrained model\n",
        "model = ResNet50(weights='imagenet')\n",
        "\n",
        "##\n",
        "training_feature_vectors = []\n",
        "query_feature_vectors = []\n",
        "\n",
        "PATH = 0\n",
        "CAT  = 1\n",
        "intermediate_layer_model = Model(inputs=model.input, \\\n",
        "                                 outputs=model.get_layer('avg_pool').output)\n",
        "for category in range(1, 2):\n",
        "    ctr  = 0\n",
        "    print(\"Starting category #\", category)\n",
        "    for im in training_paths[category]:\n",
        "        img = image.load_img(im[0], target_size=(224, 224))\n",
        "        img_data = image.img_to_array(img)\n",
        "        img_data = np.expand_dims(img_data, axis=0)\n",
        "        img_data = preprocess_input(img_data)\n",
        "        emb = intermediate_layer_model.predict(img_data)\n",
        "        np_emb = np.array(emb).flatten()\n",
        "        training_feature_vectors.append(np_emb)\n",
        "        ctr += 1\n",
        "    for im in query_paths[category]:\n",
        "        img = image.load_img(im[0], target_size=(224, 224))\n",
        "        img_data = image.img_to_array(img)\n",
        "        img_data = np.expand_dims(img_data, axis=0)\n",
        "        img_data = preprocess_input(img_data)\n",
        "        emb = intermediate_layer_model.predict(img_data)\n",
        "        np_emb = np.array(emb).flatten()\n",
        "        query_feature_vectors.append(np_emb)\n",
        "        ctr += 1\n",
        "    print(\"# images in cat\", category, \"=\", ctr)\n",
        "\n",
        "np.savez(\"feature-dump.npz\", emb_training = training_feature_vectors, emb_query = query_feature_vectors)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Splitting done\n",
            "DONE\n",
            "Starting category # 1\n",
            "# images in cat 1 = 98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V2SlVZiXDGOT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "outputId": "1b2c23fe-81b5-445d-deb0-25f99dc89135"
      },
      "cell_type": "code",
      "source": [
        "print(query_paths[1])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['./datasets/caltech256/001.ak47/001_0073.jpg', 1], ['./datasets/caltech256/001.ak47/001_0049.jpg', 1], ['./datasets/caltech256/001.ak47/001_0082.jpg', 1], ['./datasets/caltech256/001.ak47/001_0012.jpg', 1], ['./datasets/caltech256/001.ak47/001_0046.jpg', 1], ['./datasets/caltech256/001.ak47/001_0095.jpg', 1], ['./datasets/caltech256/001.ak47/001_0010.jpg', 1], ['./datasets/caltech256/001.ak47/001_0067.jpg', 1], ['./datasets/caltech256/001.ak47/001_0094.jpg', 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wu2kZIQC0sZu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "outputId": "01105f2a-9ca9-4ced-94f3-e66d7dc286a2"
      },
      "cell_type": "code",
      "source": [
        "print(len(training_feature_vectors))\n",
        "print(len(training_feature_vectors[0]))\n",
        "print(training_paths[1][0])\n",
        "from keras.preprocessing import image\n",
        "img = image.load_img(training_paths[1][0][0], target_size=(224, 224))\n",
        "\n",
        "print(\"here\")\n",
        "img_data = image.img_to_array(img)\n",
        "img_data = np.expand_dims(img_data, axis=0)\n",
        "img_data = preprocess_input(img_data)\n",
        "emb = intermediate_layer_model.predict(img_data)\n",
        "np_emb = np.array(emb).flatten()\n",
        "print(np_emb[0], np_emb[2047])\n",
        "print(training_feature_vectors[0][0], training_feature_vectors[0][2047])\n",
        "\n",
        "np.savez(\"true-classes.npz\", tr_paths = training_paths, qr_paths = query_paths)\n",
        "f=np.load(\"true-classes.npz\")\n",
        "print(f.files)\n",
        "p = f['qr_paths']\n",
        "print(len(p))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "89\n",
            "2048\n",
            "['./datasets/caltech256/001.ak47/001_0044.jpg', 1]\n",
            "here\n",
            "0.45707077 6.4322433\n",
            "0.45707077 6.4322433\n",
            "['tr_paths', 'qr_paths']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-7ef135a33257>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"true-classes.npz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'qr_paths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 return format.read_array(bytes,\n\u001b[1;32m    261\u001b[0m                                          \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                                          pickle_kwargs=self.pickle_kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# The array contained Python objects. We need to unpickle the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m             raise ValueError(\"Object arrays cannot be loaded when \"\n\u001b[0m\u001b[1;32m    693\u001b[0m                              \"allow_pickle=False\")\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpickle_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "sEwht1WGECgH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "liCfQG7OECnx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z4Yot_PSECqv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7bQrFRCwECzA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ui3GqF3NJ96T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "b4428fd2-e306-4995-f9d6-a8b2e52f5e39"
      },
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!cp true-classes.npz drive/My\\ Drive/"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datasets  drive  extracted.txt\tfeature-dump.npz  sample_data  true-classes.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bZ0rIe3tnMLz",
        "colab_type": "code",
        "outputId": "f305dd83-cfd9-41df-aca9-b876a9c5b645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        }
      },
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!mkdir drive/My\\ Drive/dumps\n",
        "!cp feature-dump.npz drive/My\\ Drive/dumps/resnet50-pretrained-np-dump.npz\n",
        "!cp feature-dump.npz drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datasets  drive  extracted.txt\tfeature-dump.npz  sample_data\n",
            "mkdir: cannot create directory ‘drive/My Drive/dumps’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lrrACX6Cnxqw",
        "colab_type": "code",
        "outputId": "d251a59a-441f-44ec-c1b6-efd5c5128b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "cell_type": "code",
      "source": [
        "!ls drive/My\\ Drive/dumps"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "resnet50-pretrained-np-dump.npz\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}